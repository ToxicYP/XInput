@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {{ECCV} submission ID 00324, supplied as supplemental material {\tt 00324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}

@book{ECCV2022,
    editor = {Shai Avidan and Gabriel Brostow and Moustapha Cissé and Giovanni Maria Farinella and Tal Hassner},
    title = {Computer Vision – ECCV 2022},
    year = {2022},
    publisher = {Springer},
    doi = {10.1007/978-3-031-19769-7}
}

@article{tong2020ma_MACRNN,
  title={MA-CRNN: a multi-scale attention CRNN for Chinese text line recognition in natural scenes},
  author={Tong, Guofeng and Li, Yong and Gao, Huashuai and Chen, Huairong and Wang, Hao and Yang, Xiang},
  journal={International Journal on Document Analysis and Recognition (IJDAR)},
  volume={23},
  pages={103--114},
  year={2020},
  publisher={Springer}
}

@article{shi2016end_CRNN,
  title={An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition},
  author={Shi, Baoguang and Bai, Xiang and Yao, Cong},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={39},
  number={11},
  pages={2298--2304},
  year={2016},
  publisher={IEEE}
}

@InProceedings{bautista2022parseq,
  title={Scene Text Recognition with Permuted Autoregressive Sequence Models},
  author={Bautista, Darwin and Atienza, Rowel},
  booktitle={European Conference on Computer Vision},
  pages={178--196},
  month={10},
  year={2022},
  publisher={Springer Nature Switzerland},
  address={Cham},
  doi={10.1007/978-3-031-19815-1_11},
  url={https://doi.org/10.1007/978-3-031-19815-1_11}
}

@inproceedings{fujitake2024dtrocr,
  title={Dtrocr: Decoder-only transformer for optical character recognition},
  author={Fujitake, Masato},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={8025--8035},
  year={2024}
}

@article{zhao2023clip4str,
  title={CLIP4STR: A Simple Baseline for Scene Text Recognition with Pre-trained Vision-Language Model},
  author={Zhao, Shuai and Wang, Xiaohan and Zhu, Linchao and Yang, Yi},
  journal={arXiv preprint arXiv:2305.14014},
  year={2023}
}

@article{zhao2021handwritten_bttr,
  title={Handwritten Mathematical Expression Recognition with Bidirectionally Trained Transformer},
  author={Zhao, Wenqi and Gao, Liangcai and Yan, Zuoyu and Peng, Shuai and Du, Lin and Zhang, Ziyin},
  journal={arXiv preprint arXiv:2105.02412},
  year={2021}
}

@inproceedings{guan2023self_SIGAT,
  title={Self-supervised Implicit Glyph Attention for Text Recognition},
  author={Guan, Tongkun and Gu, Chaochen and Tu, Jingzheng and Yang, Xue and Feng, Qi and Zhao, Yudi and Shen, Wei},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15285--15294},
  year={2023}
}

@inproceedings{jiang2023revisiting_MAERec,
  title={Revisiting scene text recognition: A data perspective},
  author={Jiang, Qing and Wang, Jiapeng and Peng, Dezhi and Liu, Chongyu and Jin, Lianwen},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={20543--20554},
  year={2023}
}

@article{shi2018aster_Aster,
  title={Aster: An attentional scene text recognizer with flexible rectification},
  author={Shi, Baoguang and Yang, Mingkun and Wang, Xinggang and Lyu, Pengyuan and Yao, Cong and Bai, Xiang},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={41},
  number={9},
  pages={2035--2048},
  year={2018},
  publisher={IEEE}
}

@inproceedings{yu2020towards_SRN,
  title={Towards accurate scene text recognition with semantic reasoning networks},
  author={Yu, Deli and Li, Xuan and Zhang, Chengquan and Liu, Tao and Han, Junyu and Liu, Jingtuo and Ding, Errui},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={12113--12122},
  year={2020}
}

@inproceedings{wan2020textscanner,
  title={Textscanner: Reading characters in order for robust scene text recognition},
  author={Wan, Zhaoyi and He, Minghang and Chen, Haoran and Bai, Xiang and Yao, Cong},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={07},
  pages={12120--12127},
  year={2020}
}

@inproceedings{qiao2020seed_se_Aster,
  title={Seed: Semantics enhanced encoder-decoder framework for scene text recognition},
  author={Qiao, Zhi and Zhou, Yu and Yang, Dongbao and Zhou, Yucan and Wang, Weiping},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={13528--13537},
  year={2020}
}

@inproceedings{baek2021if_TRBA_discuss,
  title={What if we only use real datasets for scene text recognition? toward scene text recognition with fewer labels},
  author={Baek, Jeonghun and Matsui, Yusuke and Aizawa, Kiyoharu},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={3113--3122},
  year={2021}
}

@inproceedings{wang2021two_VisionLAN,
  title={From two to one: A new scene text recognizer with visual language modeling network},
  author={Wang, Yuxin and Xie, Hongtao and Fang, Shancheng and Wang, Jing and Zhu, Shenggao and Zhang, Yongdong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={14194--14203},
  year={2021}
}

@inproceedings{fang2021read_ABInet,
  title={Read like humans: Autonomous, bidirectional and iterative language modeling for scene text recognition},
  author={Fang, Shancheng and Xie, Hongtao and Wang, Yuxin and Mao, Zhendong and Zhang, Yongdong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={7098--7107},
  year={2021}
}

@inproceedings{atienza2021vision_VITSTR,
  title={Vision transformer for fast and efficient scene text recognition},
  author={Atienza, Rowel},
  booktitle={International Conference on Document Analysis and Recognition},
  pages={319--334},
  year={2021},
  organization={Springer}
}

@inproceedings{da2022levenshtein_LevOCR,
  title={Levenshtein OCR},
  author={Da, Cheng and Wang, Peng and Yao, Cong},
  booktitle={European Conference on Computer Vision},
  pages={322--338},
  year={2022},
  organization={Springer}
}

@inproceedings{na2022multi_matrn,
  title={Multi-modal text recognition networks: Interactive enhancements between visual and semantic features},
  author={Na, Byeonghu and Kim, Yoonsik and Park, Sungrae},
  booktitle={European Conference on Computer Vision},
  pages={446--463},
  year={2022},
  organization={Springer}
}

@article{wang2022petr_Petr,
  title={Petr: Rethinking the capability of transformer-based language model in scene text recognition},
  author={Wang, Yuxin and Xie, Hongtao and Fang, Shancheng and Xing, Mengting and Wang, Jing and Zhu, Shenggao and Zhang, Yongdong},
  journal={IEEE Transactions on Image Processing},
  volume={31},
  pages={5585--5598},
  year={2022},
  publisher={IEEE}
}

@inproceedings{yang2022reading_DiGVITB,
  title={Reading and writing: Discriminative and generative modeling for self-supervised text recognition},
  author={Yang, Mingkun and Liao, Minghui and Lu, Pu and Wang, Jing and Zhu, Shenggao and Luo, Hualin and Tian, Qi and Bai, Xiang},
  booktitle={Proceedings of the 30th ACM International Conference on Multimedia},
  pages={4214--4223},
  year={2022}
}

@article{aberdam2023clipter_parseq+clipter,
  title={CLIPTER: Looking at the Bigger Picture in Scene Text Recognition},
  author={Aberdam, Aviad and Bensa{\"\i}d, David and Golts, Alona and Ganz, Roy and Nuriel, Oren and Tichauer, Royee and Mazor, Shai and Litman, Ron},
  journal={arXiv preprint arXiv:2301.07464},
  year={2023}
}

@inproceedings{cubuk2020randaugment,
  title={Randaugment: Practical automated data augmentation with a reduced search space},
  author={Cubuk, Ekin D and Zoph, Barret and Shlens, Jonathon and Le, Quoc V},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops},
  pages={702--703},
  year={2020}
}

@article{jaderberg2014synthetic_MJ,
  title={Synthetic data and artificial neural networks for natural scene text recognition},
  author={Jaderberg, Max and Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1406.2227},
  year={2014}
}

@inproceedings{gupta2016synthetic_ST,
  title={Synthetic data for text localisation in natural images},
  author={Gupta, Ankush and Vedaldi, Andrea and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2315--2324},
  year={2016}
}

@article{veit2016coco_Coco,
  title={Coco-text: Dataset and benchmark for text detection and recognition in natural images},
  author={Veit, Andreas and Matera, Tomas and Neumann, Lukas and Matas, Jiri and Belongie, Serge},
  journal={arXiv preprint arXiv:1601.07140},
  year={2016}
}

@inproceedings{shi2017icdar2017_RCTW17,
  title={Icdar2017 competition on reading chinese text in the wild (rctw-17)},
  author={Shi, Baoguang and Yao, Cong and Liao, Minghui and Yang, Mingkun and Xu, Pei and Cui, Linyan and Belongie, Serge and Lu, Shijian and Bai, Xiang},
  booktitle={2017 14th iapr international conference on document analysis and recognition (ICDAR)},
  volume={1},
  pages={1429--1434},
  year={2017},
  organization={IEEE}
}

@inproceedings{zhang2017uber_Uber,
  title={Uber-text: A large-scale dataset for optical character recognition from street-level imagery},
  author={Zhang, Ying and Gueguen, Lionel and Zharkov, Ilya and Zhang, Peter and Seifert, Keith and Kadlec, Ben},
  booktitle={SUNw: Scene Understanding Workshop-CVPR},
  volume={2017},
  pages={5},
  year={2017}
}

@inproceedings{chng2019icdar2019_art,
  title={Icdar2019 robust reading challenge on arbitrary-shaped text-rrc-art},
  author={Chng, Chee Kheng and Liu, Yuliang and Sun, Yipeng and Ng, Chun Chet and Luo, Canjie and Ni, Zihan and Fang, ChuanMing and Zhang, Shuaitao and Han, Junyu and Ding, Errui and others},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={1571--1576},
  year={2019},
  organization={IEEE}
}

@inproceedings{sun2019icdar_LSVT,
  title={ICDAR 2019 competition on large-scale street view text with partial labeling-RRC-LSVT},
  author={Sun, Yipeng and Ni, Zihan and Chng, Chee-Kheng and Liu, Yuliang and Luo, Canjie and Ng, Chun Chet and Han, Junyu and Ding, Errui and Liu, Jingtuo and Karatzas, Dimosthenis and others},
  booktitle={2019 International Conference on Document Analysis and Recognition (ICDAR)},
  pages={1557--1562},
  year={2019},
  organization={IEEE}
}

@inproceedings{nayef2019icdar2019_MLT19,
  title={ICDAR2019 robust reading challenge on multi-lingual scene text detection and recognition—RRC-MLT-2019},
  author={Nayef, Nibal and Patel, Yash and Busta, Michal and Chowdhury, Pinaki Nath and Karatzas, Dimosthenis and Khlif, Wafa and Matas, Jiri and Pal, Umapada and Burie, Jean-Christophe and Liu, Cheng-lin and others},
  booktitle={2019 International conference on document analysis and recognition (ICDAR)},
  pages={1582--1587},
  year={2019},
  organization={IEEE}
}

@inproceedings{zhang2019icdar_ReCTS,
  title={Icdar 2019 robust reading challenge on reading chinese text on signboard},
  author={Zhang, Rui and Zhou, Yongsheng and Jiang, Qianyi and Song, Qi and Li, Nan and Zhou, Kai and Wang, Lei and Wang, Dong and Liao, Minghui and Yang, Mingkun and others},
  booktitle={2019 international conference on document analysis and recognition (ICDAR)},
  pages={1577--1581},
  year={2019},
  organization={IEEE}
}

@inproceedings{singh2021textocr_TextOCR,
  title={Textocr: Towards large-scale end-to-end reasoning for arbitrary-shaped scene text},
  author={Singh, Amanpreet and Pang, Guan and Toh, Mandy and Huang, Jing and Galuba, Wojciech and Hassner, Tal},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={8802--8812},
  year={2021}
}

@article{krasin2017openimages_openimages,
  title={Openimages: A public dataset for large-scale multi-label and multi-class image classification},
  author={Krasin, Ivan and Duerig, Tom and Alldrin, Neil and Ferrari, Vittorio and Abu-El-Haija, Sami and Kuznetsova, Alina and Rom, Hassan and Uijlings, Jasper and Popov, Stefan and Veit, Andreas and others},
  journal={Dataset available from https://github. com/openimages},
  volume={2},
  number={3},
  pages={18},
  year={2017}
}

@inproceedings{krylov2021open_openvino,
  title={Open images v5 text annotation and yet another mask text spotter},
  author={Krylov, Ilya and Nosov, Sergei and Sovrasov, Vladislav},
  booktitle={Asian Conference on Machine Learning},
  pages={379--389},
  year={2021},
  organization={PMLR}
}


@inproceedings{mishra2012scene_iii5k,
  title={Scene text recognition using higher order language priors},
  author={Mishra, Anand and Alahari, Karteek and Jawahar, CV},
  booktitle={BMVC-British machine vision conference},
  year={2012},
  organization={BMVA}
}

@article{risnumawan2014robust_cute80,
  title={A robust arbitrary text detection system for natural scene images},
  author={Risnumawan, Anhar and Shivakumara, Palaiahankote and Chan, Chee Seng and Tan, Chew Lim},
  journal={Expert Systems with Applications},
  volume={41},
  number={18},
  pages={8027--8048},
  year={2014},
  publisher={Elsevier}
}

@inproceedings{wang2011end_SVt,
  title={End-to-end scene text recognition},
  author={Wang, Kai and Babenko, Boris and Belongie, Serge},
  booktitle={2011 International conference on computer vision},
  pages={1457--1464},
  year={2011},
  organization={IEEE}
}

@inproceedings{phan2013recognizing_svtp,
  title={Recognizing text with perspective distortion in natural scenes},
  author={Phan, Trung Quy and Shivakumara, Palaiahnakote and Tian, Shangxuan and Tan, Chew Lim},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={569--576},
  year={2013}
}

@inproceedings{karatzas2013icdar_IC13,
  title={ICDAR 2013 robust reading competition},
  author={Karatzas, Dimosthenis and Shafait, Faisal and Uchida, Seiichi and Iwamura, Masakazu and i Bigorda, Lluis Gomez and Mestre, Sergi Robles and Mas, Joan and Mota, David Fernandez and Almazan, Jon Almazan and De Las Heras, Lluis Pere},
  booktitle={2013 12th international conference on document analysis and recognition},
  pages={1484--1493},
  year={2013},
  organization={IEEE}
}

@inproceedings{karatzas2015icdar_IC15,
  title={ICDAR 2015 competition on robust reading},
  author={Karatzas, Dimosthenis and Gomez-Bigorda, Lluis and Nicolaou, Anguelos and Ghosh, Suman and Bagdanov, Andrew and Iwamura, Masakazu and Matas, Jiri and Neumann, Lukas and Chandrasekhar, Vijay Ramaseshan and Lu, Shijian and others},
  booktitle={2015 13th international conference on document analysis and recognition (ICDAR)},
  pages={1156--1160},
  year={2015},
  organization={IEEE}
}


@article{long2020unrealtext_sensitive4test,
  title={Unrealtext: Synthesizing realistic scene text images from the unreal world},
  author={Long, Shangbang and Yao, Cong},
  journal={arXiv preprint arXiv:2003.10608},
  year={2020}
}


@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{dosovitskiy2020image_vit,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@article{ye2023ureader_llmocr,
  title={Ureader: Universal ocr-free visually-situated language understanding with multimodal large language model},
  author={Ye, Jiabo and Hu, Anwen and Xu, Haiyang and Ye, Qinghao and Yan, Ming and Xu, Guohai and Li, Chenliang and Tian, Junfeng and Qian, Qi and Zhang, Ji and others},
  journal={arXiv preprint arXiv:2310.05126},
  year={2023}
}

@inproceedings{li2023trocr,
  title={Trocr: Transformer-based optical character recognition with pre-trained models},
  author={Li, Minghao and Lv, Tengchao and Chen, Jingye and Cui, Lei and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Li, Zhoujun and Wei, Furu},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={11},
  pages={13094--13102},
  year={2023}
}

@article{zeng2023large_llmocr,
  title={Large language models for robotics: A survey},
  author={Zeng, Fanlong and Gan, Wensheng and Wang, Yongheng and Liu, Ning and Yu, Philip S},
  journal={arXiv preprint arXiv:2311.07226},
  year={2023}
}

@article{coquenet2023dan_llmocr,
  title={DAN: a segmentation-free document attention network for handwritten document recognition},
  author={Coquenet, Denis and Chatelain, Cl{\'e}ment and Paquet, Thierry},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@inproceedings{lee2016recursive_R2AM,
  title={Recursive recurrent nets with attention modeling for ocr in the wild},
  author={Lee, Chen-Yu and Osindero, Simon},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2231--2239},
  year={2016}
}

@article{elbasani2021gcrnn,
  title={GCRNN: graph convolutional recurrent neural network for compound--protein interaction prediction},
  author={Elbasani, Ermal and Njimbouom, Soualihou Ngnamsie and Oh, Tae-Jin and Kim, Eung-Hee and Lee, Hyun and Kim, Jeong-Dong},
  journal={BMC bioinformatics},
  volume={22},
  number={5},
  pages={1--14},
  year={2021},
  publisher={BioMed Central}
}

@inproceedings{borisyuk2018rosetta,
  title={Rosetta: Large scale system for text detection and recognition in images},
  author={Borisyuk, Fedor and Gordo, Albert and Sivakumar, Viswanath},
  booktitle={Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={71--79},
  year={2018}
}
